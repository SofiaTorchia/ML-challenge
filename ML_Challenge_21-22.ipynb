{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 2021/2022 - Challenge \n",
    "\n",
    "<hr>\n",
    "\n",
    "# Identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "yourNameSurname='Sofia Torchia' # e.g., yourNameSurname='Mario Rossi'\n",
    "yourMatricolaNumber='1679164' # e.g., yourMatricolaNumber='12345678'\n",
    "yourStudentEMAIL='torchia.1679164@studenti.uniroma1.it' # e.g., yourStudentEMAIL='rossim.12345678@studenti.uniroma1.it'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 1. Mandatory Rules:\n",
    "- This year the results of the challenges will count 11,2/28 of your final grade (full info about grades <a href='https://twiki.di.uniroma1.it/twiki/view/ApprAuto '>here</a>).\n",
    "- Only one submission is allowed. We will not consider multiple submissions.\n",
    "- Please remember your solution must be <b>\"YOUR SOLUTION\"</b>, hence you are requested to deliver your individual answers/arguments/opinions/critics.\n",
    "- Mail your solution (with your <b>jupyter notebook</b> and the cleaned dataset) only to stefano.faralli@uniroma1.it <b>deadlines are announced on the ML google group and <a href='https://twiki.di.uniroma1.it/twiki/view/ApprAuto'>here</a> (NO EXCEPTIONS)</b> if you miss to deliver your solution you must wait the next (if any) available deadline. \n",
    "- The subject of your email must be: \"[ML-21-22-Challenge_solution] NAME - SURNAME - MATRICOLA\".\n",
    "- Double check the subject of your email and the attachments.\n",
    "- In case you want to compress the attachment, <b>USE ONLY STANDARD ZIP compression</b> (NO RAR,7Z etc..).\n",
    "- <b>Please sumbit The notebook (with SAVED OUTPUTS) and the cleaned dataset!</b>.\n",
    "- Your solution might be considered as the \"copy\" of others solutions, in that specific case the resulting score for all involved students will be 0/8.\n",
    "- Then read carefully all the part of the jupyter notebook and fill all fields.\n",
    "- <b>solutions (and correspondig points) are evaluated mainly on your thoughts/comments/opinions</b>.  \n",
    "- If you have questions <b>Don't write \"personal\" emails</b> to Stefano Faralli, instead <b>use our google group</b>.\n",
    "- A solution having a summary discussion with less than 500 words is evaluated with 0 points.\n",
    "- Comments summary etc.. must be in <b>English</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "### Dataset and task Description:\n",
    "<img width='400' src='news-online.jpeg'/>\n",
    "\n",
    "- The challenge is about online news popularity;\n",
    "- The provided dataset consists of one single csv file (\"OnlineNewsPopularity.csv\");\n",
    "- The provided dataset is a modified <b>noisy</b> version of the original dataset described in [1];\n",
    "\n",
    "[1] K. Fernandes, P. Vinagre and P. Cortez. A Proactive Intelligent Decision\n",
    "    Support System for Predicting the Popularity of Online News. Proceedings\n",
    "    of the 17th EPIA 2015 - Portuguese Conference on Artificial Intelligence,\n",
    "    September, Coimbra, Portugal\n",
    "\n",
    "\n",
    "This dataset summarizes a heterogeneous set of features about articles published by Mashable in a period of two years. The goal of the task is to predict the number of shares in social networks (popularity).\n",
    "\n",
    "Number of Instances: <b>39,797</b> \n",
    "\n",
    "Number of Attributes: <b>61</b>\n",
    "\n",
    "Target: <b>shares</b>\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "<table>\n",
    " <tr><th> index </th><th>name</th><th>description</th></tr>\n",
    " <tr><td>0</td><td>url</td><td>URL of the article</td></tr>\n",
    " <tr><td>1</td><td>timedelta</td><td>Days between the article publication and the dataset acquisition</td></tr>\n",
    " <tr><td>2</td><td>n_tokens_title</td><td>Number of words in the title</td></tr>\n",
    " <tr><td>3</td><td>n_tokens_content</td><td>Number of words in the content</td></tr>\n",
    " <tr><td>4</td><td>n_unique_tokens</td><td>Rate of unique words in the content</td></tr>\n",
    " <tr><td>5</td><td>n_non_stop_words</td><td>Rate of non-stop words in the content</td></tr>\n",
    " <tr><td>6</td><td>n_non_stop_unique_tokens</td><td>Rate of unique non-stop words in content</td></tr>\n",
    " <tr><td>7</td><td>num_hrefs</td><td>Number of links</td></tr>\n",
    " <tr><td>8</td><td>num_self_hrefs</td><td>Number of links to other articles published by Mashable</td></tr>\n",
    " <tr><td>9</td><td>num_imgs</td><td>Number of images</td></tr>\n",
    " <tr><td>10</td><td>num_videos</td><td>Number of videos</td></tr>\n",
    " <tr><td>11</td><td>average_token_length</td><td>Average length of the words in the content</td></tr>\n",
    " <tr><td>12</td><td>num_keywords</td><td>Number of keywords in the metadata</td></tr>\n",
    " <tr><td>13</td><td>data_channel_is_lifestyle</td><td>Is data channel 'Lifestyle'?</td></tr>\n",
    " <tr><td>14</td><td>data_channel_is_entertainment</td><td>Is data channel 'Entertainment'?</td></tr>\n",
    " <tr><td>15</td><td>data_channel_is_bus</td><td>Is data channel 'Business'?</td></tr>\n",
    " <tr><td>16</td><td>data_channel_is_socmed</td><td>Is data channel 'Social Media'?</td></tr>\n",
    " <tr><td>17</td><td>data_channel_is_tech</td><td>Is data channel 'Tech'?</td></tr>\n",
    " <tr><td>18</td><td>data_channel_is_world</td><td>Is data channel 'World'?</td></tr>\n",
    " <tr><td>19</td><td>kw_min_min</td><td>Worst keyword (min. shares)</td></tr>\n",
    " <tr><td>20</td><td>kw_max_min</td><td>Worst keyword (max. shares)</td></tr>\n",
    " <tr><td>21</td><td>kw_avg_min</td><td>Worst keyword (avg. shares)</td></tr>\n",
    " <tr><td>22</td><td>kw_min_max</td><td>Best keyword (min. shares)</td></tr>\n",
    " <tr><td>23</td><td>kw_max_max</td><td>Best keyword (max. shares)</td></tr>\n",
    " <tr><td>24</td><td>kw_avg_max</td><td>Best keyword (avg. shares)</td></tr>\n",
    " <tr><td>25</td><td>kw_min_avg</td><td>Avg. keyword (min. shares)</td></tr>\n",
    " <tr><td>26</td><td>kw_max_avg</td><td>Avg. keyword (max. shares)</td></tr>\n",
    " <tr><td>27</td><td>kw_avg_avg</td><td>Avg. keyword (avg. shares)</td></tr>\n",
    " <tr><td>28</td><td>self_reference_min_shares</td><td>Min. shares of referenced articles in Mashable</td></tr>\n",
    " <tr><td>29</td><td>self_reference_max_shares</td><td>Max. shares of referenced articles in Mashable</td></tr>\n",
    " <tr><td>30</td><td>self_reference_avg_sharess</td><td>Avg. shares of referenced articles in Mashable</td></tr>\n",
    " <tr><td>31</td><td>weekday_is_monday</td><td>Was the article published on a Monday?</td></tr>\n",
    " <tr><td>32</td><td>weekday_is_tuesday</td><td>Was the article published on a Tuesday?</td></tr>\n",
    " <tr><td>33</td><td>weekday_is_wednesday</td><td>Was the article published on a Wednesday?</td></tr>\n",
    " <tr><td>34</td><td>weekday_is_thursday</td><td>Was the article published on a Thursday?</td></tr>\n",
    " <tr><td>35</td><td>weekday_is_friday</td><td>Was the article published on a Friday?</td></tr>\n",
    " <tr><td>36</td><td>weekday_is_saturday</td><td>Was the article published on a Saturday?</td></tr>\n",
    " <tr><td>37</td><td>weekday_is_sunday</td><td> Was the article published on a Sunday?</td></tr>\n",
    " <tr><td>38</td><td>is_weekend</td><td>Was the article published on the weekend?</td></tr>\n",
    " <tr><td>39</td><td>LDA_00</td><td>Closeness to LDA topic 0</td></tr>\n",
    " <tr><td>40</td><td>LDA_01</td><td>Closeness to LDA topic 1</td></tr>\n",
    " <tr><td>41</td><td>LDA_02</td><td>Closeness to LDA topic 2</td></tr>\n",
    " <tr><td>42</td><td>LDA_03</td><td>Closeness to LDA topic 3</td></tr>\n",
    " <tr><td>43</td><td>LDA_04</td><td>Closeness to LDA topic 4</td></tr>\n",
    " <tr><td>44</td><td>global_subjectivity</td><td>Text subjectivity</td></tr>\n",
    " <tr><td>45</td><td>global_sentiment_polarity</td><td>Text sentiment polarity</td></tr>\n",
    " <tr><td>46</td><td>global_rate_positive_words</td><td>Rate of positive words in the content</td></tr>\n",
    " <tr><td>47</td><td>global_rate_negative_words</td><td> Rate of negative words in the content</td></tr>\n",
    " <tr><td>48</td><td>rate_positive_words</td><td>Rate of positive words among non-neutral tokens</td></tr>\n",
    " <tr><td>49</td><td>rate_negative_words</td><td>Rate of negative words among non-neutral tokens</td></tr>\n",
    " <tr><td>50</td><td>avg_positive_polarity</td><td>Avg. polarity of positive words</td></tr>\n",
    " <tr><td>51</td><td>min_positive_polarity</td><td>Min. polarity of positive words</td></tr>\n",
    " <tr><td>52</td><td>max_positive_polarity</td><td>Max. polarity of positive words</td></tr>\n",
    " <tr><td>53</td><td>avg_negative_polarity</td><td>Avg. polarity of negative words</td></tr>\n",
    " <tr><td>54</td><td>min_negative_polarity</td><td>Min. polarity of negative words</td></tr>\n",
    " <tr><td>55</td><td>max_negative_polarity</td><td>Max. polarity of negative words</td></tr>\n",
    " <tr><td>56</td><td>title_subjectivity</td><td>Title subjectivity</td></tr>\n",
    " <tr><td>57</td><td>title_sentiment_polarity</td><td>Title polarity</td></tr>\n",
    " <tr><td>58</td><td>abs_title_subjectivity</td><td>Absolute subjectivity level</td></tr>\n",
    " <tr><td>59</td><td>abs_title_sentiment_polarity</td><td>Absolute polarity level</td></tr>\n",
    "     <tr><td>60</td><td>shares</td><td>Number of shares (target)</td></tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# 2. Pre-processing (up to 3 of 11.2 points)     \n",
    "     \n",
    "     \n",
    "## 2.1 Clean and Load the Dataset (up to 1 of 11.2 points)\n",
    "Use the following two cells (a code cell and, a markdown cell) to: \n",
    "- create a pandas DataFrame by loading a cleaned version of the \"OnlineNewsPopularity.cvs\" file.  \n",
    "- describe the identified noise and the methodology used to fix the problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write here the code for 2.1 Load the Dataset\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your comments for step 2.1 Clean and Load the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sofiatorchia/.python-environments/default/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (9,10,37,60) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "original_data = pd.read_csv('OnlineNewsPopularity_cleaned.csv')\n",
    "#1. alla riga 39537 elimino una virgola di troppo manualmente, questo caricato è già il dataset senza questa virgola\n",
    "# ora ho un warning: Columns (9,10,37,60) have mixed types.Specify dtype option on import or set low_memory=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambio i nomi delle colonne\n",
    "original_data.columns \n",
    "columns = [col.replace(' ','') for col in original_data.columns]\n",
    "original_data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la colonna 0 deve essere di url (quindi stringhe). devo anche controllare che siano veramente url\n",
    "# decido di rimuovere tutte le righe del dataset originale in cui non c'è un url. \n",
    "col = original_data.columns[0]\n",
    "ty = original_data[col].apply(lambda x: 'http://' in x)\n",
    "i = ty[ty==False].index\n",
    "original_data.drop(index=i, inplace=True)\n",
    "\n",
    "original_data[col].isna().any() #non ci sono na, quindi in teoria la colonna è a posto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prima di guardare colonna per colonna cerco gli NA in tutto il dataset: ongi colonna tranne la 0 ha NA\n",
    "original_data.isna().any()[original_data.isna().any()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prima di togliere gli NA guardo se le colonne hanno elementi di tipo diverso\n",
    "# oppure troppo diversi dalla media.\n",
    "# per ogni NA devo controllare com'è la riga e com'è la colonna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39643</th>\n",
       "      <td>http://mashable.com/2014/12/27/son-pays-off-mo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  timedelta  \\\n",
       "39643  http://mashable.com/2014/12/27/son-pays-off-mo...        NaN   \n",
       "\n",
       "       n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "39643             NaN               NaN              NaN               NaN   \n",
       "\n",
       "       n_non_stop_unique_tokens  num_hrefs  num_self_hrefs num_imgs  ...  \\\n",
       "39643                       NaN        NaN             NaN      NaN  ...   \n",
       "\n",
       "      min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "39643                   NaN                    NaN                    NaN   \n",
       "\n",
       "       min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "39643                    NaN                    NaN                 NaN   \n",
       "\n",
       "       title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "39643                       NaN                     NaN   \n",
       "\n",
       "       abs_title_sentiment_polarity  shares  \n",
       "39643                           NaN     NaN  \n",
       "\n",
       "[1 rows x 61 columns]"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#controllo la colonna 1\n",
    "col = original_data.columns[1]\n",
    "original_data[col].value_counts() # ci sono tante classi, alcune sono in minoranza\n",
    "\n",
    "original_data[col].isna().any() \n",
    "original_data[original_data[col].isna()] # mi rendo conto che è una riga vuota (tranne per l'url), quindi la rimuovo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = original_data[original_data[col].isna()].index\n",
    "original_data.drop(index=i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56,)"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.isna().any()[original_data.isna().any()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nelle righe 13,14...,18,31..36,38   le classi sono 2 quindi gli NA si trovano facili, uso simple inputer, ma vedo se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo una funzione che trova i tipi anomali\n",
    "def anomal_types(original_data,col,t):\n",
    "    cond = original_data[col].apply(lambda x:type(x)!= t)\n",
    "    return original_data[cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potrei decidere di usare un metodo per colonne per tutte quelle colonne con classi \"corpose\"\n",
    "# guardo se una riga con tutti o quasi na ha un link già presente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39643\n",
      "6872\n"
     ]
    }
   ],
   "source": [
    "# colonna 9: trasformo la stringa ' n.a' in un pd.NA\n",
    "col = original_data.columns[9]\n",
    "a = anomal_types(original_data,col,float)\n",
    "print(original_data.shape[0])\n",
    "print(a.shape[0]) \n",
    "cond2 = original_data[col][cond].apply(lambda x: 'n.a.' in x)\n",
    "i = original_data[col][cond][cond2].index\n",
    "original_data.loc[i,col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colonna 9: le stringhe diventano float\n",
    "col = original_data.columns[9]\n",
    "cond = original_data[col].apply(lambda x: type(x)==str)\n",
    "for i in original_data[col][cond].index:\n",
    "    original_data.loc[i,col] = float(original_data.loc[i,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomal_types(original_data,col,float)\n",
    "original_data.loc[38062,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colonna 37, trasformo 'n.a.' e '0.0'\n",
    "col = original_data.columns[37]\n",
    "a = anomal_types(original_data,col,float)\n",
    "cond2 = original_data[col][cond].apply(lambda x: 'n.a.' in x)\n",
    "i = original_data[col][cond][cond2].index\n",
    "original_data.loc[i,col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = original_data.columns[37]\n",
    "cond = original_data[col].apply(lambda x: type(x)==str)\n",
    "for i in original_data[col][cond].index:\n",
    "    original_data.loc[i,col] = float(original_data.loc[i,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = original_data.columns[60]\n",
    "cond = original_data[col].apply(lambda x: type(x)==str)\n",
    "a = anomal_types(original_data,col,int)\n",
    "cond2 = original_data[col][cond].apply(lambda x: 'n.a.' in x)\n",
    "i = original_data[col][cond][cond2].index\n",
    "original_data.loc[i,col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = original_data.columns[60]\n",
    "cond = original_data[col].apply(lambda x: type(x)==str)\n",
    "for i in original_data[col][cond].index:\n",
    "    original_data.loc[i,col] = int(original_data.loc[i,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = original_data.columns[10]\n",
    "cond = original_data[col].apply(lambda x: type(x)==str)\n",
    "a = anomal_types(original_data,col,float)\n",
    "cond2 = original_data[col][cond].apply(lambda x: 'n.a.' in x)\n",
    "i = original_data[col][cond][cond2].index\n",
    "original_data.loc[i,col] = np.nan\n",
    "for i in original_data[col][cond].index:\n",
    "    original_data.loc[i,col] = float(original_data.loc[i,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [url, timedelta, n_tokens_title, n_tokens_content, n_unique_tokens, n_non_stop_words, n_non_stop_unique_tokens, num_hrefs, num_self_hrefs, num_imgs, num_videos, average_token_length, num_keywords, data_channel_is_lifestyle, data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world, kw_min_min, kw_max_min, kw_avg_min, kw_min_max, kw_max_max, kw_avg_max, kw_min_avg, kw_max_avg, kw_avg_avg, self_reference_min_shares, self_reference_max_shares, self_reference_avg_sharess, weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday, weekday_is_saturday, weekday_is_sunday, is_weekend, LDA_00, LDA_01, LDA_02, LDA_03, LDA_04, global_subjectivity, global_sentiment_polarity, global_rate_positive_words, global_rate_negative_words, rate_positive_words, rate_negative_words, avg_positive_polarity, min_positive_polarity, max_positive_polarity, avg_negative_polarity, min_negative_polarity, max_negative_polarity, title_subjectivity, title_sentiment_polarity, abs_title_subjectivity, abs_title_sentiment_polarity, shares]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 61 columns]"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = original_data.columns[0]\n",
    "original_data[col].isna().any() \n",
    "if(original_data[col].isna().any()):\n",
    "    i = original_data[original_data[col].isna()].index\n",
    "    #print(original_data.loc[i])\n",
    "#print(original_data[col].value_counts())\n",
    "anomal_types(original_data,col,str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37909, 38062]\n"
     ]
    }
   ],
   "source": [
    "# cerco le righe con almeno un NA\n",
    "ind = []\n",
    "for i in original_data.index:\n",
    "    if(original_data.loc[i].isna().any()):\n",
    "        ind.append(i)\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.loc[35154,'weekday_is_sunday'] = 0.0  # era già segnato un altro giorno come 1.0, quindi questo doveva\n",
    "                                                    # per forza essere 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per queste righe prima faccio il simple inputer su determinate colonne: 13,14...,18,31..36,38\n",
    "# non conviene, tolgo le righe.\n",
    "binary_columns = []\n",
    "for col in original_data.columns:\n",
    "    s = original_data[col].value_counts().shape[0]\n",
    "    if s == 2:\n",
    "        binary_columns.append(col)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "\n",
    "for col in binary_columns:\n",
    "    X = np.array(original_data[col]).reshape(-1,1)\n",
    "    y = imp.fit_transform(X)\n",
    "    original_data[col] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rimuovo le righe con troppe incognite\n",
    "original_data.drop(index = [36261, 39590, 39646], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timedelta                               37.0\n",
       "n_tokens_title                           9.0\n",
       "n_tokens_content                         0.0\n",
       "n_unique_tokens                          0.0\n",
       "n_non_stop_words                         0.0\n",
       "n_non_stop_unique_tokens                 0.0\n",
       "num_hrefs                                0.0\n",
       "num_self_hrefs                           0.0\n",
       "num_imgs                                 0.0\n",
       "num_videos                               1.0\n",
       "average_token_length                     0.0\n",
       "num_keywords                             8.0\n",
       "data_channel_is_lifestyle                0.0\n",
       "data_channel_is_entertainment            0.0\n",
       "data_channel_is_bus                      0.0\n",
       "data_channel_is_socmed                   0.0\n",
       "data_channel_is_tech                     0.0\n",
       "data_channel_is_world                    0.0\n",
       "kw_min_min                              -1.0\n",
       "kw_max_min                              88.0\n",
       "kw_avg_min                         12.454286\n",
       "kw_min_max                               0.0\n",
       "kw_max_max                          843300.0\n",
       "kw_avg_max                          482275.0\n",
       "kw_min_avg                               0.0\n",
       "kw_max_avg                       7176.152519\n",
       "kw_avg_avg                         4709.2604\n",
       "self_reference_min_shares                0.0\n",
       "self_reference_max_shares                0.0\n",
       "self_reference_avg_sharess               0.0\n",
       "weekday_is_monday                        0.0\n",
       "weekday_is_tuesday                       1.0\n",
       "weekday_is_wednesday                     0.0\n",
       "weekday_is_thursday                      0.0\n",
       "weekday_is_friday                        0.0\n",
       "weekday_is_saturday                      0.0\n",
       "weekday_is_sunday                        0.0\n",
       "is_weekend                               0.0\n",
       "LDA_00                              0.025004\n",
       "LDA_01                              0.181113\n",
       "LDA_02                                 0.025\n",
       "LDA_03                              0.743882\n",
       "LDA_04                                 0.025\n",
       "global_subjectivity                      0.0\n",
       "global_sentiment_polarity                0.0\n",
       "global_rate_positive_words               0.0\n",
       "global_rate_negative_words               0.0\n",
       "rate_positive_words                      0.0\n",
       "rate_negative_words                      0.0\n",
       "avg_positive_polarity                    0.0\n",
       "min_positive_polarity                    0.0\n",
       "max_positive_polarity                    0.0\n",
       "avg_negative_polarity                    0.0\n",
       "min_negative_polarity                    0.0\n",
       "max_negative_polarity                    0.0\n",
       "title_subjectivity                       0.0\n",
       "title_sentiment_polarity                 0.0\n",
       "abs_title_subjectivity                   0.5\n",
       "abs_title_sentiment_polarity             0.0\n",
       "shares                                   NaN\n",
       "Name: 37909, dtype: object"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.loc[37909]['timedelta':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per la riga 38062 faccio knn \n",
    "# original_data.loc[38062]['timedelta':]\n",
    "# escludo la prima colonna da knn perchè fa solo danni\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "X = np.array(original_data.loc[0:][original_data.columns[1:]])\n",
    "imp = KNNImputer()\n",
    "imp.fit(X)\n",
    "X = imp.transform(X)\n",
    "df = pd.DataFrame(X,columns = original_data.columns[1:],index = original_data.index)\n",
    "df.insert(0,'url',original_data.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39639</th>\n",
       "      <td>http://mashable.com/2014/12/27/nypd-rafael-ram...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1629.0</td>\n",
       "      <td>0.425711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.606092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.429534</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39640</th>\n",
       "      <td>http://mashable.com/2014/12/27/protests-contin...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.653153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.825758</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39641</th>\n",
       "      <td>http://mashable.com/2014/12/27/samsung-app-aut...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>0.529052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684783</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.260000</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39642</th>\n",
       "      <td>http://mashable.com/2014/12/27/seth-rogen-jame...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.696296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.885057</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.211111</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39645</th>\n",
       "      <td>http://mashable.com/2014/12/27/ukraine-blasts/</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0.539493</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692661</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.205246</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39640 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  timedelta  \\\n",
       "0      http://mashable.com/2013/01/07/amazon-instant-...      731.0   \n",
       "1      http://mashable.com/2013/01/07/ap-samsung-spon...      731.0   \n",
       "2      http://mashable.com/2013/01/07/apple-40-billio...      731.0   \n",
       "3      http://mashable.com/2013/01/07/astronaut-notre...      731.0   \n",
       "4       http://mashable.com/2013/01/07/att-u-verse-apps/      731.0   \n",
       "...                                                  ...        ...   \n",
       "39639  http://mashable.com/2014/12/27/nypd-rafael-ram...        8.0   \n",
       "39640  http://mashable.com/2014/12/27/protests-contin...        8.0   \n",
       "39641  http://mashable.com/2014/12/27/samsung-app-aut...        8.0   \n",
       "39642  http://mashable.com/2014/12/27/seth-rogen-jame...        8.0   \n",
       "39645     http://mashable.com/2014/12/27/ukraine-blasts/        8.0   \n",
       "\n",
       "       n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0                12.0             219.0         0.663594               1.0   \n",
       "1                 9.0             255.0         0.604743               1.0   \n",
       "2                 9.0             211.0         0.575130               1.0   \n",
       "3                 9.0             531.0         0.503788               1.0   \n",
       "4                13.0            1072.0         0.415646               1.0   \n",
       "...               ...               ...              ...               ...   \n",
       "39639            13.0            1629.0         0.425711               1.0   \n",
       "39640            11.0             223.0         0.653153               1.0   \n",
       "39641            11.0             346.0         0.529052               1.0   \n",
       "39642            12.0             328.0         0.696296               1.0   \n",
       "39645             6.0             682.0         0.539493               1.0   \n",
       "\n",
       "       n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
       "0                      0.815385        4.0             2.0       1.0  ...   \n",
       "1                      0.791946        3.0             1.0       1.0  ...   \n",
       "2                      0.663866        3.0             1.0       1.0  ...   \n",
       "3                      0.665635        9.0             0.0       1.0  ...   \n",
       "4                      0.540890       19.0            19.0      20.0  ...   \n",
       "...                         ...        ...             ...       ...  ...   \n",
       "39639                  0.606092       15.0            12.0       6.0  ...   \n",
       "39640                  0.825758        5.0             3.0       1.0  ...   \n",
       "39641                  0.684783        9.0             7.0       1.0  ...   \n",
       "39642                  0.885057        9.0             7.0       3.0  ...   \n",
       "39645                  0.692661       10.0             1.0       1.0  ...   \n",
       "\n",
       "       min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0                   0.100000                   0.70              -0.350000   \n",
       "1                   0.033333                   0.70              -0.118750   \n",
       "2                   0.100000                   1.00              -0.466667   \n",
       "3                   0.136364                   0.80              -0.369697   \n",
       "4                   0.033333                   1.00              -0.220192   \n",
       "...                      ...                    ...                    ...   \n",
       "39639               0.033333                   1.00              -0.429534   \n",
       "39640               0.214286                   0.80              -0.250000   \n",
       "39641               0.100000                   0.75              -0.260000   \n",
       "39642               0.136364                   0.70              -0.211111   \n",
       "39645               0.062500                   0.50              -0.205246   \n",
       "\n",
       "       min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                     -0.600              -0.200000            0.500000   \n",
       "1                     -0.125              -0.100000            0.000000   \n",
       "2                     -0.800              -0.133333            0.000000   \n",
       "3                     -0.600              -0.166667            0.000000   \n",
       "4                     -0.500              -0.050000            0.454545   \n",
       "...                      ...                    ...                 ...   \n",
       "39639                 -1.000              -0.050000            0.783333   \n",
       "39640                 -0.250              -0.250000            0.000000   \n",
       "39641                 -0.500              -0.125000            0.100000   \n",
       "39642                 -0.400              -0.100000            0.300000   \n",
       "39645                 -0.500              -0.012500            0.000000   \n",
       "\n",
       "       title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                     -0.187500                0.000000   \n",
       "1                      0.000000                0.500000   \n",
       "2                      0.000000                0.500000   \n",
       "3                      0.000000                0.500000   \n",
       "4                      0.136364                0.045455   \n",
       "...                         ...                     ...   \n",
       "39639                 -0.600000                0.283333   \n",
       "39640                  0.000000                0.500000   \n",
       "39641                  0.000000                0.400000   \n",
       "39642                  1.000000                0.200000   \n",
       "39645                  0.000000                0.500000   \n",
       "\n",
       "       abs_title_sentiment_polarity  shares  \n",
       "0                          0.187500   593.0  \n",
       "1                          0.000000   711.0  \n",
       "2                          0.000000  1500.0  \n",
       "3                          0.000000  1200.0  \n",
       "4                          0.136364   505.0  \n",
       "...                             ...     ...  \n",
       "39639                      0.600000  1400.0  \n",
       "39640                      0.000000  1200.0  \n",
       "39641                      0.000000  1800.0  \n",
       "39642                      1.000000  1900.0  \n",
       "39645                      0.000000  1100.0  \n",
       "\n",
       "[39640 rows x 61 columns]"
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Dataset Analysis (up to 1 of 11.2 points)\n",
    "In the following code cell (feel free to create new cells), remember to comment your code snippets:\n",
    "\n",
    "1) Print the total number of samples;\n",
    "\n",
    "2) Print a table with the first 15 samples;\n",
    "\n",
    "3) Plot the histogram distribution of \"shares\";\n",
    "\n",
    "4) A bar chart counting the attributes:  data_channel_is_lifestyle, data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write here the code for 2.2 Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your comments for step 2.2 Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Feature importance analysis  (up to 1 of 11.2 points)\n",
    "\n",
    "Perform feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write here the code for 2.4 Feature importance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your comments for step 2.4 Feature importance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 3. Model Selection (up to 8.2 of 11.2  points)\n",
    "In this part of the challenge you are requested to perform all the necessary steps required in order to design a full fledged classification task on the <b>shares</b> feature.\n",
    "\n",
    "You are requested to perform the following steps having in mind the following: \n",
    "\n",
    "1) the dataset must be properly splitted to perform crossvalidation \n",
    "\n",
    "2) when required, features must be properly encoded\n",
    "\n",
    "3) in order to simplify the problem the target feature can be dicretized <b>(number of classes must be >=5)</b> ;\n",
    "\n",
    "4) for model selection you are requested to consider: \n",
    "\n",
    "- Decision Trees\n",
    "\n",
    "- Support Vector Machines;\n",
    "\n",
    "- An ensamble methodology;\n",
    "\n",
    "- MLPNs.\n",
    "\n",
    "5) hyper-parameter tuning <b>must</b> be performed and discussed;\n",
    "\n",
    "6) apply standardizion and normalization when appropriate;\n",
    "\n",
    "7) remember to use an appropriate evaluation setting (cross-fold etc..)\n",
    "\n",
    "8) describe the measures adopted for the evaluation and discuss the results;\n",
    "\n",
    "9) provide a discussion of the model selection, where you describe the differences in terms of performance and explains the root causes;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write here the code for step 3 Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write here your comments for step 3 Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# 4. Summary\n",
    "Provide a summary discussion (in English) of your solution <b>(at least 500 words)</b> feel free to include plots figures and tables.\n",
    "\n",
    "<b>This is a mandatory step</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write here <b>your own</b> summary dicussion (in English) use at least 500 words, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
